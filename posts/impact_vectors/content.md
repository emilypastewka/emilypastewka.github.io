<!--
.. date: 2025-07-26
.. tags: career, ai, cleantech, ecommerce
-->

# Impact Vectors

As I wrote when I [first](../../pages/about/) launched this blog, I've always aimed to use my time to make the world a better place. It sounds like a clear goal, but figuring out how to accomplish it hasn't always been easy. Read a little bit about effective altruism [[1]](#1) and you may find yourself questioning whether a career as a financier with a philanthropic streak isn't in fact a better way to invest your effort than at a non-profit. On the other hand, maybe it makes sense to put less effort into work and instead prioritize thinking and acting locally: making good day-to-day decisions in your community, raising conscientious global citizens at home.

Recently, I've found it helpful to think about my impact as a Euclidean vector, having both **direction** and **magnitude**. By envisioning a vector to represent the impact of each job I've held, or jobs I consider taking, I can easily compare them. What's more, vectors are additive: I can vectorize decisions across various parts of my life and sum them to get an idea of my total impact on the world at any point in time, or normalize them by time spent in each role and find a measure of my cumulative impact.

**Direction**

I constrain my impact vectors to 180 degrees, where 180 degrees is Negative impact, 0 degrees is Positive impact, and 90 degrees is Neutral.

**Magnitude**

The length of an impact vector corresponds to how great the impact is on the world: greater vector magnitude equates to greater impact.

## Examples

I spent many years at Uber and Rent the Runway, both of which I believed would have a positive impact on the world. The sharing economy promised to reduce total consumption by matching supply and demand of a common pool of resources.

Uber, of course, operated at global scale. What's more, transportation is a massive part of the climate equation. Potential impact felt not only directionally positive, but large.
 ![Uber Hope](../../images/impact_vectors/Impact%20Vectors%20-%20Uber%20hope.jpg)

Rent the Runway operated in the US only, smaller magnitude.
 ![RTR Hope](../../images/impact_vectors/Impact%20Vectors%20-%20RTR%20hope.jpg)

Unfortunately, both were ultimately hampered (in my view) by the profit motive.

Uber cancelled Pool and slowed down investment in autonomous vehicles.
 ![Uber Actual](../../images/impact_vectors/Impact%20Vectors%20-%20Uber%20actual.jpg)

Rent the Runway put ever more focus toward embracing rapid fashion cycles, acquiring and selling through inventory to keep up rather than remaining focused on creating the new paradigm it had originally promised.
 ![RTR Actual](../../images/impact_vectors/Impact%20Vectors%20-%20RTR%20actual.jpg)

Today, I work on [climate problems](../energy_tech_data_problems/) at Palmetto. I've never questioned the alignment of this company under the leadership of [Chris Kemper](https://palmetto.com/leadership/christopher-kemper). In terms of magnitude, [electrifying everything](https://www.amazon.com/Electrify-Optimists-Playbook-Energy-Future/dp/0262046237) is a key part of moving the needle toward an abundant energy future, but we're US only (many energy companies find it hard to cross international borders, given heavy government regulation over power grids), and still focused only on residential.
 ![Palmetto](../../images/impact_vectors/Impact%20Vectors%20-%20Palmetto.jpg)

A big question today is what the [impact of AI](../ai_in_climate_tech/) will be. It seems clear that the magnitude will be enormous â€” this technology may be [unprecedented](../../pages/snippets/the_unprecedented/) to such an extent that we can't even guess at how far the vector reaches, and debate rages about directionality, as well.

Job loss, geopolitical instability, and misaligned superintelligence lead to fears that AI companies may be pointing far in the negative direction.
 ![AI Bad Case](../../images/impact_vectors/Impact%20Vectors%20-%20AI%20bad%20case.jpg)


But if companies like Anthropic [[2]](#2) build AI that helps us [transform the world for the better](https://www.darioamodei.com/essay/machines-of-loving-grace), the impact vector may be off the charts on the positive side in a way that we've never seen.
 ![AI Good Case](../../images/impact_vectors/Impact%20Vectors%20-%20AI%20good%20case.jpg)

## Uncertainty

Of course, individual vectors only allow for point estimates on both dimensions. Whether you believe AI is pointing toward the red or the green, for instance, committing resources either way is currently a bet with an unknown outcome. But assuming you are [well-hired into a role and will bring a comparative advantage to a company's probability of success](../rocket_ships/), [putting your time and energy toward working on any given bet](../../pages/snippets/focus_on_one_thing_land_it/) [increases the probability that that company realizes the impact you believe it can have](../../pages/snippets/be_hypothesis_driven/).

Not everything is in our control, but if you are uniquely positioned to bring about the future you hope to see, then tightening the uncertainty around a vector pointed in the right direction may be an excellent use of your time.

___

#### [1]
The fun way to do this is to read Going Infinite by Michael Lewis.

#### [2]
Importantly, as a Public Benefit Corporation under a [Long Term Benefit Trust](https://www.anthropic.com/news/the-long-term-benefit-trust), Anthropic is _not_ hampered by the profit motive in the same way that most companies are.
