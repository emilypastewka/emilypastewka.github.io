<!--
.. date: 2025-05-02
.. tags: cleantech, startups, ai
-->

# AI In Climate Tech: Recognizing & Reconciling the Cognitive Dissonance

More and more my conversations as a data leader and climate leader have overlapped: AI has been on everyone's mind for years now, but in recent months both the utility of AI tools and awareness of the energy intensity of AI seem to have skyrocketed. In tech circles, both are challenges to be tackled: can we continue to extract more value from AI, and do so at less cost? In climate circles, there's a greater cognitive dissonance: can we own both realities? Is doing so moral, ethical, and optimal for the future of humanity and the planet?

I'm writing in the immediate wake of SF Climate Week [[1]](#1), which admittedly is a bit of a bubble when it comes to the overlap of AI and Energy, but it was refreshing to spend time among so many others who see not only the joint opportunity from the technologists' viewpoint but also how this moment is driving deeper focus on the energy challenges at the heart of the climate crisis.

## The question

Investment is required to make progress. Financially, startups operate for many years in the red thanks to venture funding — climate tech companies included. We accept this risk, and we are judicious with capital in service of achieving our goals.

Today, AI is "in the red" with regards to energy consumption, but highly valuable to make progress on climate issues. I'm not just thinking about projects centered around using AI directly to optimize the grid, predict and respond to natural disasters, or discover new materials that can better sequester carbon [[2]](#2) — I am also speaking to the raw urgency of the crisis, and how speed to solution matters. AI tooling helps humans do more work faster. It enables progress, and when harnessed by those working to drive progress in clean energy and climate, it serves that agenda the same way other energy-consuming activities do: charging laptops; eating food; air travel. We trust that using non-renewables to power our offices and flying around the world for important meetings will contribute more to our progress than to the problem. We don't yet have that trust for AI. Should we? How do we get there?

## My answers

I strongly believe that AI will, in the end, be a bigger part of the solution than the problem. What got me to that viewpoint? What will it take to get others along for the ride?

Part of the challenge is the newness of AI and subsequent lack of normalization as a daily tool. Consider: many extant technologies are not proven to be carbon-neutral, we've just had time to get used to the idea of leveraging them. Though many large companies have set ambitious climate goals, carbon accounting results are still not shared publicly, and accounting activities are rarely undertaken at smaller companies [[3]](#3). I can't say for sure that every flight I get on does more to further progress in this space than it does to accelerate the very crisis we're trying to solve, but we've grown accustomed to the idea that this form of investment is acceptable to drive progress. Time normalizes.

Many people's optimism remains limited by a lack of understanding of just how powerful AI can be for people in a wide range of roles.Depending on the contours of one’s online echo chamber, it’s still common to associate AI primarily with Ghibli-style pet portraits, selfie enhancements, or LinkedIn listicles. Some tried using tools like ChatGPT early on and found them underwhelming; others haven’t yet developed the prompting fluency required to unlock real value. Even those who prioritize data over anecdotes may find themselves unsatisfied, as rigorous studies on AI’s impact lag behind the rapid pace of its adoption [[4]](#4).

Finally, some may be bought in on the power of AI and yet still wonder if the costs are too high to justify the promise. Research papers and news stories present clear, easy-to-consume figures on the energy and climate costs of AI: carbon per query, datacenter growth per hyperscaler, fresh water consumption per flop [[5]](#5). Consistent with what drives internet engagement from us predictable humans, stories about the real progress being made in AI compute efficiency don't make as much noise or stick around as long about those decrying its risks. But the progress here has been astounding, and — importantly — incentives to continue this progress are entirely aligned with the capitalist profit motive [[6]](#6). Consuming vast quantifies of dirty energy is expensive. Startups and hyperscalers alike are investing heavily (and making massive progress) on ways to provide datacenters with constant access to renewables, and to reduce the energy intensity of both training and inference [[7]](#7). We're not there yet, but much the way smartphone demand drove breakthroughs in battery technology and supply chains, signs point to AI progress driving positive externalities like accelerating efforts to stabilize and decarbonize the grid. We may struggle to accept the paradox of aligning ourselves with those adding strain and cost to the grid, but if we recognize that "the enemy of my enemy is my friend," we'll realize these friends are extremely smart, rich, and powerful allies.

Putting it all together comes back to what appears to be the word of the year: abundance. While Ezra Klein and Derek Thompson's buzzy ideology has its own specific definition (and this overlaps heavily with how I think about the term), I first connected the word to the future of energy in 2023, after reading a Packy McCormick [article](https://www.notboring.co/p/the-morality-of-having-kids-in-a) about the simulation hypothesis. This piece lays out human history as "a big, long game called ENERGY" [[8]](#8), and argues that human progress, human problems, and discovering/inventing new sources of energy to fuel the former and solve the latter are inextricably intertwined. This ties closely to my broader identification as a [techno-optimist](../../pages/snippets/solutions_orientation/) [[9]](#9)


---

#### [[1]]
I co-hosted the official energy hackathon. Trust me, this is completely unbiased: it was the most fun event of the week.

#### [[2]]
And so much more. I wrote about [data x climate](../energy_tech_data_problems/) a few years ago, but here are some of my recent favorites:
* optimize the grid: Utilidata, Tapestry, Camus
* predict and respond to natural disasters and large-scale climate shifts: Silurian.ai, First Street, Rhizome, Brightband
* discover new materials that can better sequester carbon: Argonne, CuspAI, Orbital Materials

#### [[3]]
For small startups, reporting protocols like Scope 1-3 are typically not expected...except climate startups! Our investors have often promised portfolio-level reporting to their LPs.

#### [[4]]
Business school publications, consultancies, e.g. publish survey-based research, but I'm looking for something harder showing that we have moved beyond Solow's paradox.

#### [[5]]
Leaving a positive stat here instead: [Stanford's 2025 AI Index](https://hai.stanford.edu/ai-index) finds that energy efficiency has improved by 40% each year.

#### [[6]]
A bit shocked that I don't have a prior post to link to here. Misaligned incentives under capitalism have been the reason I left 3 jobs.

#### [[7]]
I've recently started to tell people who want to work on climate that optimizing AI compute might be the most impactful thing they could work on. The best part is that projects like these are happening all over the industry:
* model distillation & pruning
* edge inference
* hardware awareness
* carbon-aware job scheduling & dynamic compute scaling
    * cross-datacenter training
    * "follow the sun"
    * can't help but name 2 specific companies: Crusoe and Ceramic are really cool

#### [[8]]
Earlier this year I finally got around to reading Sapiens by Yuval Noah Harari*. He makes a similar claim (though my interpretation of the last page of the book is that his goal for writing it was not actually oriented around galvanizing energy innovation but rather deep thought around what we really want and should expect out of genetic modification).

I also reference this piece [here](../rocket_ships/).

#### [[9]]
While not referenced on that snippet, I believe Ezra Klein articulated this viewpoint very well on a 2023 or 2024 podcast episode as well.
